{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165b528f-67f8-479a-bbdf-192f9e13dc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import xml.etree.ElementTree as ET\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ed462c-91e2-4f8b-9890-23be5d1b1131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Custom Dataset Class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataset_path, split, transform=None):\n",
    "        self.dataset_path = dataset_path\n",
    "        self.split = split\n",
    "        self.transform = transform\n",
    "        self.images = []\n",
    "        self.annotations = []\n",
    "\n",
    "        split_dir = os.path.join(dataset_path, split)\n",
    "        images_dir = os.path.join(split_dir, \"images\")\n",
    "        annotations_dir = os.path.join(split_dir, \"annotations\")\n",
    "\n",
    "        for filename in os.listdir(images_dir):\n",
    "            if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "                image_path = os.path.join(images_dir, filename)\n",
    "                self.images.append(image_path)\n",
    "\n",
    "                annotation_path = os.path.join(annotations_dir, os.path.splitext(filename)[0] + \".xml\")\n",
    "                tree = ET.parse(annotation_path)\n",
    "                root = tree.getroot()\n",
    "                annotation = []\n",
    "\n",
    "                for obj in root.findall(\"object\"):\n",
    "                    name = obj.find(\"name\").text\n",
    "                    bbox = obj.find(\"bndbox\")\n",
    "                    xmin = int(bbox.find(\"xmin\").text)\n",
    "                    ymin = int(bbox.find(\"ymin\").text)\n",
    "                    xmax = int(bbox.find(\"xmax\").text)\n",
    "                    ymax = int(bbox.find(\"ymax\").text)\n",
    "                    annotation.append((xmin, ymin, xmax, ymax))\n",
    "\n",
    "                self.annotations.append(annotation)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.images[index]\n",
    "        image = Image.open(image_path).convert(\"L\")  \n",
    "        annotation = self.annotations[index]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        boxes = torch.as_tensor(annotation, dtype=torch.float32)\n",
    "        labels = torch.ones((len(annotation),), dtype=torch.int64)  \n",
    "\n",
    "        return image, {\"boxes\": boxes, \"labels\": labels}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd8803b-ad51-490f-a357-b248ab6b1749",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Test the dataset\n",
    "dataset_path = \"dataset\"  \n",
    "split = \"train\"  \n",
    "thermal_transform = transforms.Compose([\n",
    "    transforms.Resize((800, 800)),\n",
    "    transforms.RandomHorizontalFlip(0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "thermal_dataset = CustomDataset(dataset_path, split, thermal_transform)\n",
    "print(f\"Number of images in the dataset: {len(thermal_dataset)}\")\n",
    "image, target = thermal_dataset[0]\n",
    "print(f\"Image shape: {image.shape}\")\n",
    "print(f\"Target boxes: {target['boxes']}\")\n",
    "print(f\"Target labels: {target['labels']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22f6551-03b4-49ce-aa75-28c340899847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Dataset Preprocessing\n",
    "def preprocess_dataset(dataset):\n",
    "    preprocessed_images = []\n",
    "    preprocessed_annotations = []\n",
    "    \n",
    "    for image, target in dataset:\n",
    "        if isinstance(image, torch.Tensor):\n",
    "            image = transforms.ToPILImage()(image)\n",
    "        else:\n",
    "            image = Image.fromarray(image)\n",
    "        \n",
    "        image = thermal_transform(image) \n",
    "        \n",
    "        boxes = target['boxes']\n",
    "        labels = target['labels']\n",
    "        \n",
    "        _, height, width = image.shape\n",
    "        boxes[:, [0, 2]] /= width\n",
    "        boxes[:, [1, 3]] /= height\n",
    "        \n",
    "        target = {'boxes': boxes, 'labels': labels}\n",
    "        \n",
    "        preprocessed_images.append(image)\n",
    "        preprocessed_annotations.append(target)\n",
    "    \n",
    "    return preprocessed_images, preprocessed_annotations\n",
    "\n",
    "# Test the preprocessing function\n",
    "preprocessed_images, preprocessed_annotations = preprocess_dataset(thermal_dataset)\n",
    "print(f\"Number of preprocessed images: {len(preprocessed_images)}\")\n",
    "print(f\"Number of preprocessed annotations: {len(preprocessed_annotations)}\")\n",
    "print(f\"Preprocessed image shape: {preprocessed_images[0].shape}\")\n",
    "print(f\"Preprocessed annotation boxes shape: {preprocessed_annotations[0]['boxes'].shape}\")\n",
    "print(f\"Preprocessed annotation labels shape: {preprocessed_annotations[0]['labels'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba4709a-4bfd-47cb-b4fb-13313163cb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Dataset and DataLoader Creation\n",
    "dataset_path = \"dataset\"\n",
    "split = \"train\"\n",
    "\n",
    "thermal_transform = transforms.Compose([\n",
    "    transforms.Resize((800, 800)),\n",
    "    transforms.RandomHorizontalFlip(0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "thermal_dataset = CustomDataset(dataset_path, split, thermal_transform)\n",
    "\n",
    "class_labels = set()\n",
    "for _, annotation in thermal_dataset:\n",
    "    for obj in annotation:\n",
    "        name = obj[0]\n",
    "        class_labels.add(\"vehicle\")  \n",
    "\n",
    "class_to_idx = {\"vehicle\": 0}  \n",
    "print(\"Class labels:\", class_to_idx)\n",
    "\n",
    "preprocessed_thermal_images, preprocessed_thermal_annotations = preprocess_dataset(thermal_dataset)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    images = [item[0] for item in batch]\n",
    "    targets = [item[1] for item in batch]\n",
    "    \n",
    "    images = torch.stack(images, dim=0)\n",
    "    \n",
    "    return images, targets\n",
    "\n",
    "train_thermal_dataset = list(zip(preprocessed_thermal_images, preprocessed_thermal_annotations))\n",
    "train_thermal_loader = DataLoader(train_thermal_dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "for images, targets in train_thermal_loader:\n",
    "    print(f\"Batch images shape: {images.shape}\")\n",
    "    print(f\"Batch targets boxes shape: {targets[0]['boxes'].shape}\")\n",
    "    print(f\"Batch targets labels shape: {targets[0]['labels'].shape}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c6623a-9064-4031-ac93-d852c0ddb78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Model Definition and Training\n",
    "num_classes = len(class_to_idx) + 1\n",
    "\n",
    "thermal_model = fasterrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
    "in_features = thermal_model.roi_heads.box_predictor.cls_score.in_features\n",
    "thermal_model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "thermal_model.to(device)\n",
    "\n",
    "thermal_optimizer = torch.optim.SGD(thermal_model.parameters(), lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    thermal_model.train()\n",
    "    \n",
    "    thermal_epoch_loss = 0.0\n",
    "    \n",
    "    for thermal_images, thermal_targets in train_thermal_loader:\n",
    "        thermal_images = list(image.to(device) for image in thermal_images)\n",
    "        thermal_targets = [{k: v.to(device) for k, v in t.items()} for t in thermal_targets]\n",
    "        \n",
    "        thermal_loss_dict = thermal_model(thermal_images, thermal_targets)\n",
    "        thermal_losses = sum(loss for loss in thermal_loss_dict.values())\n",
    "        \n",
    "        thermal_optimizer.zero_grad()\n",
    "        thermal_losses.backward()\n",
    "        thermal_optimizer.step()\n",
    "        \n",
    "        thermal_epoch_loss += thermal_losses.item()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Thermal Loss: {thermal_epoch_loss/len(train_thermal_loader):.4f}\")\n",
    "\n",
    "torch.save(thermal_model.state_dict(), \"thermal_trained_model.pth\")\n",
    "\n",
    "thermal_model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, targets in train_thermal_loader:\n",
    "        images = list(image.to(device) for image in images)\n",
    "        outputs = thermal_model(images)\n",
    "        \n",
    "        for i in range(len(images)):\n",
    "            boxes = outputs[i]['boxes'].cpu().numpy()\n",
    "            labels = outputs[i]['labels'].cpu().numpy()\n",
    "            scores = outputs[i]['scores'].cpu().numpy()\n",
    "            \n",
    "            print(f\"Image {i+1} - Boxes: {boxes}, Labels: {labels}, Scores: {scores}\")\n",
    "        \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b54a6a-d4d1-4a78-ae65-202639ddfcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Evaluation and Testing\n",
    "def evaluate_model(model, dataloader, device):\n",
    "    model.eval()\n",
    "    \n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, targets in dataloader:\n",
    "            images = list(image.to(device) for image in images)\n",
    "            outputs = model(images)\n",
    "            \n",
    "            for output in outputs:\n",
    "                boxes = output['boxes'].cpu().numpy()\n",
    "                labels = output['labels'].cpu().numpy()\n",
    "                scores = output['scores'].cpu().numpy()\n",
    "                \n",
    "                indices = torchvision.ops.nms(torch.tensor(boxes), torch.tensor(scores), iou_threshold=0.5)\n",
    "                \n",
    "                filtered_boxes = boxes[indices]\n",
    "                filtered_labels = labels[indices]\n",
    "                filtered_scores = scores[indices]\n",
    "                \n",
    "                all_predictions.append((filtered_boxes, filtered_labels, filtered_scores))\n",
    "            \n",
    "            for target in targets:\n",
    "                boxes = target['boxes'].cpu().numpy()\n",
    "                labels = target['labels'].cpu().numpy()\n",
    "                \n",
    "                all_targets.append((boxes, labels))\n",
    "    \n",
    "    return all_predictions, all_targets\n",
    "\n",
    "test_split = \"test\"\n",
    "test_thermal_dataset = CustomDataset(dataset_path, test_split, thermal_transform)\n",
    "test_thermal_loader = DataLoader(test_thermal_dataset, batch_size=1, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "test_predictions, test_targets = evaluate_model(thermal_model, test_thermal_loader, device)\n",
    "print(f\"Number of test predictions: {len(test_predictions)}\")\n",
    "print(f\"Number of test targets: {len(test_targets)}\")\n",
    "print(f\"Test prediction boxes shape: {test_predictions[0][0].shape}\")\n",
    "print(f\"Test prediction labels shape: {test_predictions[0][1].shape}\")\n",
    "print(f\"Test prediction scores shape: {test_predictions[0][2].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ba4cbe-2489-43b6-8927-980eabef9771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Load the trained model\n",
    "thermal_model.load_state_dict(torch.load(\"thermal_trained_model.pth\"))\n",
    "thermal_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc26e762-2ad1-4d30-aabe-95c025616211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Prepare the test dataset\n",
    "test_split = \"test\"\n",
    "test_thermal_dataset = CustomDataset(dataset_path, test_split, thermal_transform)\n",
    "test_thermal_loader = DataLoader(test_thermal_dataset, batch_size=1, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9280ef03-8e8f-4743-b14b-477da8ea1db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Evaluate the model on the test dataset\n",
    "test_predictions, test_targets = evaluate_model(thermal_model, test_thermal_loader, device)\n",
    "\n",
    "unique_labels = np.unique(labels)\n",
    "print(\"Unique labels:\", unique_labels)\n",
    "print(f\"Boxes: {boxes}\")\n",
    "print(f\"Labels: {labels}\")\n",
    "print(f\"Scores: {scores}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254214f9-4be4-4092-85c0-5e9b058d3c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Visualize the object detection results\n",
    "def visualize_detections(image, boxes, labels, scores, class_labels, confidence_threshold=0.3):\n",
    "    image_with_detections = image.copy()\n",
    "    \n",
    "    height, width, _ = image.shape\n",
    "    \n",
    "    if not isinstance(boxes, (list, np.ndarray)):\n",
    "        boxes = [boxes]\n",
    "    \n",
    "    if not isinstance(labels, (list, np.ndarray)):\n",
    "        labels = [labels]\n",
    "    \n",
    "    if not isinstance(scores, (list, np.ndarray)):\n",
    "        scores = [scores]\n",
    "    \n",
    "    for box, label, score in zip(boxes, labels, scores):\n",
    "        if score >= confidence_threshold:\n",
    "            if isinstance(box, (list, np.ndarray)):\n",
    "                xmin, ymin, xmax, ymax = box\n",
    "            else:\n",
    "                xmin, ymin, xmax, ymax = box, box, box, box  \n",
    "            xmin = int(xmin * width)\n",
    "            ymin = int(ymin * height)\n",
    "            xmax = int(xmax * width)\n",
    "            ymax = int(ymax * height)\n",
    "            \n",
    "            class_name = class_labels[int(label)]  \n",
    "            \n",
    "            cv2.rectangle(image_with_detections, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n",
    "            cv2.putText(image_with_detections, f\"{class_name}: {score:.2f}\", (xmin, ymin - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "    \n",
    "    return image_with_detections\n",
    "\n",
    "num_visualizations = 5\n",
    "class_labels = {1: \"vehicle\"}\n",
    "\n",
    "for i in range(num_visualizations):\n",
    "    image_path = test_thermal_dataset.images[i]\n",
    "    image = cv2.imread(image_path)  \n",
    "    \n",
    "    boxes, labels, scores = test_predictions[i]\n",
    "    \n",
    "    print(f\"Boxes: {boxes}\")\n",
    "    print(f\"Labels: {labels}\")\n",
    "    print(f\"Scores: {scores}\")\n",
    "    \n",
    "    image_with_detections = visualize_detections(image, boxes, labels, scores, class_labels)\n",
    "    \n",
    "    cv2.imshow(f\"Thermal Object Detection - Image {i+1}\", image_with_detections)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b4064a-6a69-4374-b29c-82ebe4ced3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Image Classification Dataset\n",
    "class ImageClassificationDataset(Dataset):\n",
    "    def __init__(self, image_paths, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.image_paths[index]\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        if \"smallCar\" in image_path:\n",
    "            label = 0\n",
    "        elif \"largeCar\" in image_path:\n",
    "            label = 1\n",
    "        elif \"lightTruck\" in image_path:\n",
    "            label = 2\n",
    "        elif \"heavyTruck\" in image_path:\n",
    "            label = 3\n",
    "        else:\n",
    "            label = -1  \n",
    "        \n",
    "        return image, label\n",
    "\n",
    "\n",
    "dataset = ImageClassificationDataset(vehicle_image_paths, transform=classification_transform)\n",
    "image, label = dataset[0]\n",
    "print(\"Image shape:\", image.shape)\n",
    "print(\"Label:\", label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac8e0ae-3e3d-4cf4-9a22-e1e993274132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: Image Classification Dataset Creation\n",
    "classification_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "vehicle_image_paths = [\"vehicle_images/\" + img for img in os.listdir(\"vehicle_images\")]\n",
    "\n",
    "classification_dataset = ImageClassificationDataset(vehicle_image_paths, transform=classification_transform)\n",
    "classification_dataloader = DataLoader(classification_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "\n",
    "for images, labels in classification_dataloader:\n",
    "    print(\"Batch shape:\", images.shape)\n",
    "    print(\"Labels:\", labels)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f331e4-4228-408a-8af2-0a83226528f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 13: Image Classification Model\n",
    "class_names = [\"car\", \"truck\", \"bus\", \"motorcycle\"]\n",
    "num_classes = len(class_names)\n",
    "\n",
    "classification_model = models.resnet18(pretrained=True)\n",
    "num_features = classification_model.fc.in_features\n",
    "classification_model.fc = nn.Linear(num_features, num_classes)\n",
    "\n",
    "classification_model.to(device)\n",
    "\n",
    "print(\"Model architecture:\")\n",
    "print(classification_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d874c5ef-934e-49a3-a255-376b9c77a3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 14: Image Classification Training\n",
    "classification_criterion = nn.CrossEntropyLoss()\n",
    "classification_optimizer = torch.optim.Adam(classification_model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    classification_model.train()\n",
    "    \n",
    "    for images, labels in classification_dataloader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = classification_model(images)\n",
    "        loss = classification_criterion(outputs, labels)\n",
    "        \n",
    "        classification_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        classification_optimizer.step()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Classification Loss: {loss.item():.4f}\")\n",
    "\n",
    "torch.save(classification_model.state_dict(), \"classification_model.pth\")\n",
    "\n",
    "classification_model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in classification_dataloader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = classification_model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Classification Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2914f91d-2a86-4821-8ed4-08e4927dfc2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
